### Questionnaires
- A series of questions used in gathering info from ppl, usually answered w/out the presence of a researcher
- Learning goals
    - Explain __when__ and __why__ questionnaires may be appropriate evaluation technique choice; discuss their pros & cons
        - valuable throughout the design process BUT may be executed differently depending on stage in process
            - __pre/early design__: for understanding, good for reaching lots of ppl early on
            - __mid/late design__: input on your design approach & details (prototype, alpha/beta systems, and beyond)
        - __Pros__: administration is _cheap_ (wide subject group can be reached)
        - does not require presence of a researcher
        - many results can be _quantified_
        - __Cons__: creation can be "_expensive_" (very important to get the questions right)
        - risk of _low response rate_
        - risk of _low quality responses_
    - List diff. styles of questions (open, closed, Likert, etc) and give examples of what they are appropriate for
        - Open ended
        - Closed: mc, check boxes, and ranges
        - Rating scales: Likert, semantic differential
        - Ranked
            - Ordering of items in a list
            - Useful to indicate a user's preferences
            - Forced choice
        - Combining open-ended & closed questions: gets specific response, but allows room for user's opinion (eg. Likert from disagree <--> to agree))
    - Discuss important __consideratons for designing__ and __administering__ a questionnaire
        - Establish the __purpose__ of the questionnaire
            - what info is sought? 
            - how would you analyze the results?
            - what would you do with your analysis
        - Determine the __audience__ you want to reach 
        - __pilot__ before sending it out: test the _wording_, _timing_, _validity_, _analysis_
            - can increase _validity_ by piloting, triangulation (target hypotheses with multiple questions), use previously validated questionnaires
        - Important to get the questions _right_ as you cannot ask follow-up questions
            - A few general guidelines:
                - avoid leading questions
                - consider how to order questions 
                - be specific and clear about how users should answer
                - keep questions short and easy to follow
                - avoid 'double-' and 'triple-barreled' questions
                - avoid ambiguity and too much room for interpretation
        - Trade-offs: limited by length & complexity so can't always ask everything
            - try to focus on what you really want to learn
                - a few focused questions
                - don't ask obvious questions
        - Administering questionnaires
            - in-person administration: requires time, but highest completion rate
            - "take-home" (conventional): often subjects don't complete/return the questionnaire
            - email: subjects can answer in their own time, responses are free-form, attachments may be a prolbme, response rates depend on trust in source
            - web-based forms: standardize formats and responses, Java/Javascript to ensure correct/complete
        - Be considerate of your respondents and the context you access them in: works better!
            - Questionnaire length (short is good): reasonable completion times, ask questions whose answers you will use
            - Privacy invasions: be careful how/what you ask
            - Ability: limitations like literacy and disability can come into play 
            - Motivation: why should the respondent bother? Usually need to offer sth in return,,, but be careful about introducing bias

### Summary: Questionnaires
- Establish purpose
- Determine audience
- Variety of administration methods (for diff audiences)
- Design questions
    - many kinds, depend on what you want to learn
    - most important distinction: open/closed  (like structured/unstructured interview questions)
- Be considerate of your respondents
- Motivate your respondents (without biasing them)

### Interviews
- types: structured, semi-structured, unstructured
- questions: open/closed, guidelines for good ones
- planning and conducting + recording methods

- Explain __when and why__ interviews may be appropriate evaluation technique choice
    - well suited for exploring issues, learning more about tasks, scenarios of use, involving users (& making them feel involved), getting insde the user's head, among other things

- Discuss pros and cons of interviewing
    - __Pros__: excellent for pursuing specific issues
    - More flexible than questionnaires (probe more deeply on interesting issues as they arise)
    - __Cons__: time consuming to conduct and to analyze 
    - Interviewer can bias the interview
    What interviewees say they do != what they actually do 
        (may misremember or may not want to tell the truth, if hypothetical question, can be hard to imagine)
 
- Outline criteria for a __good__ interview, and things you want to avoid doing 
    - Know your goals: planned questions/interview topics should support your data gathering goals
    - Be organized BEFORE you start: check equipment, have all necessary docs 
    - Structure the time: have a clear beginning, middle and end
    - Pilot!!! practice, practice, practice (Even very experienced interviewers do this)

### Observation
- One of the anywhere, anytime evaluation techniques
- Explain __when and why__ observations may be appropriate evaluation technique choice
    - __What?__: another __tool__ in your evaluation toolkit
    - _direct observation_: spending time with individuals observing activity as it happens
        - common approaches: _simple observation, think-aloud, co-discovery learning_, ethnography, contextual interview (interview + observation)
    - _indirect observation_: making a record of a user's activity as it happens to be studied at a later time
    - __When and why?__: valuable throughout design process
        - BUT may be executed differently depending on stage in process
            - __pre/early design__: observe for understanding user's context, tasks, and goals
            - __mid/late design__: used to investigate how well the developing design/prototype supports the tasks and goals 
- Discuss pros & cons of different observation techniques
    - __Pros__: 
        - objective - see what participant does, not says
        - flexible - can do either controlled or real context
        - rich data
    - __Cons__: 
        -observer's presence can disrupt/influence what is being observed
        - can be difficult to analyze/reproduce
        - potentially expensive, time consuming
    - __Simple observation__ (direct observation)
        - User is given the task (or not) and evaluator just watches the user
        - problem: no inisght into the user's decision process or attitude
    - __Think-aloud method__ (direct observation)
        - Subjects are asked to say what they are _thinking/doing_
            - what they believe is happening
            - what they are trying to do 
            - why they took an action
                - gives insight into what the user is thinking 
        - Problems
            - awkward/uncomfortable for subject (not normal to "think-aloud")
            "thinking: about it may alter the way ppl perform their task
            - hard to talk when they are concentrating on the problem
        - Widely used evaluation method in _industry_
    - __Co-discovery__ learning (direct observation)
        - two ppl work together on a task
            - normal conversation between the two users is monitored
            - removes awkwardness of think-aloud, more natural
            - provides insights into thinking process of both users
- Outline important considerations when planning and conducting an observation and recording data
    - Analyzing and interpreting observation data
        - _Qualitative_ data: interpreted to tell a "story", categorization and looking for themes
        - _Quantitative_ data: presented as values, tables, charts, and graphs; often treated _statistically_
        May get either kind of data depending on what you observe: plan on what to record based on what you want to use the data for
    - __Coding Sheets__ (indirect observation)
        - goal: try to obtain the data in a usable form
        - problem: the observer can introduce subjectivity into the observation (where/how can this happen?)
        - coding sheets help by...
            - adding _structure_ and _precision_ to observation
            - support _quantitative_ analysis -> counting events
            - tell observer(s) how/what to record
            - minimizes subjective contamination
        - only works if coding sheet is appropriate (piloting is important!)
        - free-form notes can also be helpful here
        - What influences coding sheet _design_?
            - What data do you need to collect? 
                - need _goals_ for your evaluation
                - goals depend on _stages of design_
            - How will you get that data?
                - Which observation method do you use?
    - Recording observations
        - Direct/in real-time: paper & pencil, typing
            - primitive but cheap
            evaluators record events, interpretations and extraneous observations
            - problems: evaluator seems disengaged, writing/typing is slow 
        - Audio recording: capture discussion (think-aloud, co-discovery)
            - hard to synchronize streams (eg. interface actions with audio)
            - transcription is slow and difficult 
        - Video recording: can see what a user is doing 
            - can be intrusive (at least initially)
            - analysis can be chalelnging (takes even longer than audio)
- Describe a contextual inquiry, its relationship to observations/interview, and when it would be an appropriate technique 

### Planning Evaluations
- Develop focus and goals for pre-design activities (eg. identify human activity needing support, stakeholders, central tasks, evaluation goals, participants - who?)
    - __Pre-design__: part of evaluation should be to reveal new issues/things you hadn't thought of (early findings inform new rounds of data gathering)
    - What you're trying to understand generally becomes increasingly specific
    - Work _backwards_ from goals to figure out what you need to do 
- Explain what it means to __triangulate__ in data gathering and evaluation
    - __triangulation__: a strategy to enhance _validity_, _credibility_
        - use the _multiple perspectives_ available from complementary sources
        - interview, observation, questionnaire: where they overlap is where TRUTH(?) lies
        - Use multiple data sources (ppl, places, times), data collection methods, researchers/evaluators
- Make and justify strategic decisions in evaluation planning 
    1. What sorts of questions _get at_ these goals? 
        - How long do kids spend reading with an e-reader compared to regular books (before getting bored)?
    2. What types of data would answer these questions? 
        - time, magnitude
    3. What evaluations could give you these types of data?
        - controlled observation
    4. Now prioritize what specific questions you want to focus on, and what methods you will use to answer them 
    5. Make a specific plan 
        - Decide what to include in a coding sheet
        - Create interview questions to ask 
        - Define a protocol for running the evaluation form from start to end
        - Plan your data analysis 
    6. Choose and combine evaluation methods 
        - Depends on goals, questions and constraints 
        - Your need for control over: __realism__ and __generalizability__ (how well do these results apply in other situations?), natural VS artifical setting, disruptive VS non-disruptive approaches, time/cost/expertise or resources available, stage of development when evaluation is performed


